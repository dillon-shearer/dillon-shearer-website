---
title: "Dillon's Data Cleaner: a small, local spreadsheet hygiene demo"
publishedAt: '2025-12-18'
summary: "A walkthrough of the new Dillons Data Cleaner demo: objectives, architecture, transforms, and why I added it to the demo lab."
---

This post walks through Dillon's Data Cleaner, the newest addition to my demo lab. I wanted a compact, browser-first companion for spreadsheet chores - a place to drop a CSV or Excel workbook, skim a preview, flip a few tidy-up switches, and leave with a cleaner file without closing the tab. Building it scratched the same itch as my gym workflow projects: ship something useful, show my approach to clean data, and let the code speak for itself.

The flow mirrors how I run projects. Upload the file, confirm headers, decide which transforms belong in the run, and sign off on the export. Nothing leaves the browser. No API calls. No mystery servers. Just a local sandbox for people who care about clean inputs as much as clean outputs.

Along the way you can:
- normalize headers and case
- reorder columns to match downstream systems
- scrub dates and numbers
- trim noisy whitespace and merge duplicates
- run quick lookups from a secondary sheet
- download an XLSX or a bundle of CSVs when the preview looks right

Under the hood I leaned on the same stack that powers the rest of this site: Next.js, React, and Tailwind, plus SheetJS for workbook parsing and JSZip for bundling multi file exports. Every transform is a pure function, so the preview never drifts from what you download, and the diff view makes it obvious what changed.

To test it I built a sample workbook with the real-life annoyances I see in client data: mis cased headers, serial number dates, duplicate orders, and lookup keys with trailing spaces. Running that file through the cleaner confirmed the transforms stack predictably, stats update in real time, and exports open without a single warning. It also added a short list of next steps like sharing the dummy data file and adding a lightweight end to end test that walks the same path as a new user.

I added Dillon's Data Cleaner to the portfolio because it fills the gap between scraping data off the glass and pushing it into a production pipeline. It is pragmatic enough to be useful today but still readable for anyone who wants to study how I approach client side data work. Clone the repo, run `npm run dev`, head to `/demos/dillons-data-cleaner`, and tell me which transform would save you the most time.
